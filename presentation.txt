랄프루프 리서치 데이

랄프루프에 대해 내가 알고 있던 것
- 어떻게든 llm을 굴려서 내가 원하는 결과 뽑아내기

이에 대한 의문
- 사람은 처음부터 완벽한 프롬프트를 줄 수 없는데, 장시간 루프가 정말 의도에 수렴한다고 보장할 수 있는가?
- 드리프트 방지는 결국 확률적 완화인데, 무인 실행의 신뢰 구간을 어떻게 정의할 수 있는가?
- 실패 비용이 큰 도메인에서는 자동화 이득보다 사후 검수 비용이 더 커지지 않는가?
- 어차피 인간 검수가 필요하다면, Ralph Loop의 실질적인 가치 경계는 어디까지인가?
- 따라서 Ralph Loop는 어떤 문제 유형에서 가장 경제성이 높은가?


일단 시작하자
- 게임 앱공장장

기술적 한계
- 랄프루프에 대해 사용 경험 X
- 유니티/flutter 등 개발 지식 X


리서치: 랄프루프 실행 방법 4가지 비교
- bash 스크립트 (while true; do claude -p): 가장 원시적, headless에서 skills 미지원
- 공식 플러그인 (/ralph-loop): 설치 간편, Stop hook 내장 → 이걸로 선택
- Oh My ClaudeCode (OMC): 멀티에이전트, 병렬 실행 가능, 학습 곡선 높음
- Claude Code Tasks: 의존성 관리/기억 목적, 루프 대체는 아님

핵심 인사이트: Tasks vs Ralph Loop
- Ralph Loop = "멈추지 마" (반복 집중)
- Tasks = "뭘 했는지 잊지 마" (기억/의존성 관리)
- 게임 아케이드는 각 게임이 독립적 → Ralph Loop이 적합

프로젝트 설계: 게임 아케이드
- AI가 사람 개입 없이 웹 게임을 지속적으로 생성하는 시스템
- 포트 8000: 프로덕트 서버 / 포트 38000: 테스트 서버

기술 선택 논의: HTML vs Python 웹 게임
- HTML/JS: AI 학습 데이터 풍부, 배포 간단, 게임 간 완전 독립 → 선택
- Python (Flask/NiceGUI): pytest 직접 가능하지만, 웹 게임 예시 적고 복잡
- 절충안 채택: HTML 게임 + JS 로직 분리 (game-logic.js)
  → 배포 편의성 + 정확한 로직 검증 동시 달성

PRD 설계 (2단계 구조)
- 마더 PRD: 고정, 전체 프로세스 정의 (8단계)
- 서브 PRD: 게임별 상세 기획서, random_seed.py 기반 자동 생성
- "천재 게임 디자이너" 페르소나 적용 → "3초 안에 조작법 이해, 30초 만에 빠져드는 게임"

random_seed.py: 게임 제약조건 랜덤 생성
- genre, theme, primary_mechanic, secondary_mechanic, difficulty_curve, visual_style
- 기존 게임과 장르+테마 중복 회피

4중 검증 전략 설계
- 가벼운 것 → 무거운 것 순서로 진행. 앞 단계 통과해야 다음 단계로.
- 실패하면 해당 단계부터 재시작, 3회 실패 시 게임 폐기 후 새 시드로 재시작

검증을 왜 이렇게 설계했는가?
- HTML 게임은 "자동 검증"이 어렵다는 게 핵심 문제
- 단일 HTML 파일이면 로직을 테스트할 방법이 Playwright밖에 없음
- Playwright만으로는 "코드 로직이 맞는지" 정밀 검증 불가
- 그래서 game-logic.js를 분리하는 절충안을 선택
  → 순수 함수로 뽑아내면 Node.js에서 유닛테스트 가능
  → 배포 편의성(HTML) + 정확한 로직 검증(Node.js) 동시 달성

검증 1단계: 유닛테스트 (game-logic.test.js)
- game-logic.js의 순수 함수를 node로 직접 테스트
- initGameState, updateState, checkCollision, isGameOver 등
- "허들에 부딪히면 isGameOver가 true 반환하는가?" 같은 정밀 검증
- 브라우저 없이 돌아가니까 빠르고 정확

검증 2단계: 린터 (html-validate + eslint)
- 문법 에러 사전 차단
- Playwright 돌리기 전에 기본적인 코드 품질 확인
- 실제로 eslint v10에서 설정 파일 포맷이 바뀌어서 에러남 → Claude Code가 알아서 고침

검증 3단계: Playwright 범용 테스트 (7개 공통 항목)
- 모든 게임에 공통 적용되는 기본 품질 체크
- 페이지 로딩, JS 에러 없음, 게임 요소 존재, 조작법 표시, 메인 링크, 키보드 반응, 점수 표시
- playwright.config.js에서 포트 38000 테스트 서버 자동 관리

검증 4단계: 시나리오 테스트 (game-scenario.spec.js)
- 이게 핵심. 유닛테스트와 레벨이 다름
- 유닛테스트 = "코드가 맞는가?" / 시나리오 테스트 = "기획 의도대로 플레이 되는가?"
- 서브 PRD에서 AI가 직접 시나리오 3개 이상을 설계
  - 시나리오 1: 정상 플레이 (키 입력 → 점수 증가 확인)
  - 시나리오 2: 실패 케이스 (충돌 → 게임오버 확인)
  - 시나리오 3: 점수 누적 & 난이도 상승
- 구체적인 키 입력 시퀀스 + 기대 결과 + 판정 기준(DOM 요소)까지 명시
- 게임마다 고유한 Playwright 테스트 코드를 자동 생성

검증 구조의 한계 (실행 후 발견)
- 4중 검증을 다 통과해도 실제 플레이하면 문제 있음
  - Sky Rhythm: 목숨 3개인데 1번 실수에 즉사
  - Sea Tower: 장식 오브젝트가 플레이어에게 데미지
- 테스트 통과 ≠ 품질 보증. "자동 검증의 커버리지"와 "체감 품질" 사이에 갭이 존재
- → 시나리오 테스트를 더 엄격하게 강화하거나, 사람이 최종 플레이 검수해야 함

로그 시스템 추가
- 매 iteration 결과를 logs/[게임이름].log에 기록
- 성공/실패 모두 기록, 게임 폴더 삭제해도 로그는 유지
- 나중에 "왜 실패했는지" 추적 가능

토큰 절약 전략
- PRD는 한글 유지 (1회만 읽으니까 영향 적음)
- 실행 프롬프트, 코드 주석, 변수명, 서브 PRD → 영어
- 유저 대면 텍스트(게임 UI, 조작법) → 한글

실행 환경 세팅 삽질기
- GCP 서버에 Node.js 없음 → Claude Code가 알아서 설치함
- git 없어서 플러그인 설치 실패 → sudo apt install git
- ralph-loop 플러그인 마켓플레이스 추가 필요 (기본 내장 아님)
- 승인 팝업 계속 뜸 → claude --dangerously-skip-permissions로 해결
- tmux로 세션 관리 (arcade: 루프 실행 / server: 포트 8000)

첫 실행 결과
- 5분 53초 만에 첫 게임 생성 완료: "Sky Rhythm" (스카이 리듬, 4레인 리듬 게임)
- 유닛테스트 20개 + 린터 + Playwright 7개 + 시나리오 3개 전부 통과
- games.json 등록, 로그 기록까지 PRD대로 수행
- 두 번째 게임: "Sea Tower" (씨 타워, 블록 쌓기 게임) - 3분 57초

발견된 문제점
1. ralph-loop 플러그인이 1회 만들고 멈춤
   - DONE 출력 시 completion-promise 달성 = 전체 완료로 해석하는 듯
   - → bash 스크립트 루프로 전환 (claude -p 반복 실행)
   - while true; do claude -p; done 원리 그대로
   - headless 모드(-p)에서 skills 미지원 이슈 있지만, 우리는 CLAUDE.md/슬래시 명령어 안 쓰고 PRD.md 직접 지시 + Playwright는 npm 패키지라 문제 없음

2. 게임 퀄리티 문제: 즉사 버그
   - Sky Rhythm: 목숨 3개인데 1번 실수하면 바로 게임오버
   - Sea Tower: 비행기가 지나가면 의도치 않게 목숨 차감
   - Star Lane: 시나리오 테스트 5/5 통과했는데도 한번 죽으면 바로 끝
   - 원인 분석: AI가 생명 시스템을 안 넣고 1히트 즉사로 만들어버림
     → 시나리오 4 "생명이 있는 게임의 경우"라고 써서 AI가 스킵해버림
   - 해결: 게임 규칙에 "최소 3개 생명, 1회 실패 시 1 감소, 0일 때만 게임오버" 강제
     → 시나리오 4를 "필수, 스킵 불가"로 변경

3. 디자인 빈약 문제
   - 단색 배경 + 단색 도형만으로 구성된 밋밋한 게임
   - 해결: 서브 PRD에 "비주얼 디자인" 섹션 추가
     → CSS 변수로 색상 팔레트 정의 필수
     → 점수 획득/게임오버/조작 시 시각적 피드백 필수 (애니메이션, 색 변화 등)
     → "단색 배경 + 단색 도형만" 금지 명시
   - 추가: "게임 오브젝트 비주얼" 가이드라인
     → 외부 이미지 사용 불가 (네트워크 의존성 제거)
     → 대신: 인라인 SVG, CSS 그라데이션/그림자, 이모지, Canvas 드로잉 활용
     → 나쁜 예시 vs 좋은 예시 코드까지 PRD에 포함 (AI가 정확히 이해하도록)

PRD 수정 → 재실행 사이클 (총 3회)
- 1차 실행: 기본 PRD → 게임은 만들어지나 즉사+디자인 빈약
- 2차 실행: 생명 시스템 강제 + 디자인 가이드라인 추가 → 여전히 즉사 (표현 애매함)
- 3차 실행: "필수, 스킵 불가" 명시 + SVG/이모지/Canvas 비주얼 가이드 추가 → 현재 진행중
- PRD 자체가 "프롬프트 엔지니어링"이라는 것을 체감
- PRD 한 줄의 애매함이 게임 품질에 직접적 영향
- 매번 기존 게임 전부 삭제 후 재실행

실행 방식 변천사
- 1차: ralph-loop 플러그인 (interactive mode) → 1회만 실행되고 멈춤
- 2차: ralph-loop 다시 시도 → 역시 1회만 실행
- 3차: bash 스크립트 루프 (claude -p --dangerously-skip-permissions) → 정상 반복 확인 중
- --verbose + tee로 실시간 로그 + 파일 저장 추가

핵심 교훈 / 느낀 점
- PRD 설계가 80%: PRD가 잘 돼있으면 AI가 거의 정확히 따름
- PRD의 애매한 표현은 AI가 유리하게 해석한다 ("생명이 있는 경우" → 생명 안 넣으면 스킵)
- 테스트가 통과해도 실제 플레이 품질은 다른 문제
- "자동 검증"과 "품질 보증"은 다르다 → 의문에서 제기했던 "사후 검수 비용" 문제가 실제로 발생
- 랄프루프의 가치 경계: "대충 많이 만들기"에는 좋지만, "잘 만들기"는 PRD 정밀도에 비례
- PRD 수정 → 재실행 사이클 자체가 "메타 랄프루프"
- 공식 플러그인(ralph-loop)이 아직 불안정 → bash 스크립트가 더 확실
- 그래도 10분 미만에 게임 1개 생성은 놀라움