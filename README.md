# 게임 아케이드 — Ralph Loop 리서치 프로젝트

AI가 사람 개입 없이 웹 게임을 지속적으로 생성하는 자동화 시스템.
Ralph Loop(Claude Code 반복 실행)를 활용한 게임 공장 실험.

---

## 프로젝트 개요

`loop.sh`가 `claude -p`를 반복 실행하면, Claude가 매 iteration마다 `PRD.md`를 읽고
새로운 미니 웹 게임을 자동으로 기획 → 구현 → 검증 → 등록한다.

```
loop.sh → claude -p → PRD.md 읽기 → 시드 생성 → 서브 PRD 작성 →
게임 코드 생성 → 4중 검증 → games.json 등록 → 로그 기록 → DONE → 반복
```

---

## 실행 방법

```bash
./run.sh
```

tmux 세션 `arcade`가 열리며 두 개의 창이 자동 실행된다.

| 창 | 역할 |
|----|------|
| `arcade:loop` | `loop.sh` — Ralph Loop 실행 |
| `arcade:server` | `python3 -m http.server 8000` — 프로덕트 서버 |

세션이 이미 열려있으면 새로 만들지 않고 attach한다.
창 전환: `Ctrl+b` → `n` (다음) 또는 `Ctrl+b` → `0`, `1`

- **포트 8000**: 완성된 게임을 서비스하는 프로덕트 서버 (수동 관리)
- **포트 38000**: 테스트 전용 서버 (Playwright가 자동 관리)

---

## 프로젝트 구조

```
toy_game_factory_ralph-loop/
├── PRD.md                      # 마더 PRD (전체 프로세스 정의, 8단계)
├── loop.sh                     # Ralph Loop 실행 스크립트
├── random_seed.py              # 게임 제약조건 랜덤 생성기
├── index.html                  # 메인 페이지 (게임 목록)
├── games.json                  # 게임 레지스트리
├── logs/
│   ├── iteration-N.log         # 루프 실행 로그
│   └── [게임이름].log          # 게임별 결과 로그
└── games/
    └── [게임이름]/
        ├── PRD.md              # 서브 PRD (게임별 기획서)
        ├── index.html          # 게임 본체
        ├── game-logic.js       # 순수 로직 (Node.js 테스트 가능)
        ├── game-logic.test.js  # 유닛 테스트
        └── game-scenario.spec.js  # Playwright 시나리오 테스트
```

---

## 핵심 설계 결정

### HTML/JS 선택 이유
- AI 학습 데이터가 풍부해 코드 품질이 높다
- 게임 간 완전 독립 → 하나가 망해도 다른 게임에 영향 없음
- 배포 간단 (정적 파일 서빙)

### game-logic.js 분리 이유
단일 HTML 파일이면 로직 검증이 Playwright뿐이라 정밀도가 낮다.
게임 로직을 순수 함수로 분리하면 Node.js에서 유닛테스트가 가능하다.
**배포 편의성(HTML) + 정확한 로직 검증(Node.js)** 동시 달성.

### 2단계 PRD 구조
- **마더 PRD**: 고정. 전체 프로세스(8단계) 정의.
- **서브 PRD**: 게임별 기획서. `random_seed.py` 출력 기반으로 매 iteration 자동 생성.

---

## 4중 검증 전략

가벼운 것 → 무거운 것 순서로 진행. 앞 단계를 통과해야 다음 단계로.

| 단계 | 도구 | 검증 대상 |
|------|------|-----------|
| 1. 유닛테스트 | `node game-logic.test.js` | 순수 로직 함수 정확성 |
| 2. 린터 | `eslint` + `html-validate` | 문법 에러 사전 차단 |
| 3. Playwright 범용 | `tests/game-test.spec.js` | 7개 공통 품질 항목 |
| 4. 시나리오 테스트 | `game-scenario.spec.js` | 기획 의도대로 플레이 되는가 |

3회 연속 실패 시 해당 게임을 폐기하고 새 시드로 재시작.

**유닛테스트 vs 시나리오 테스트의 차이**
- 유닛테스트: "코드가 맞는가?"
- 시나리오 테스트: "기획 의도대로 플레이 되는가?"

---

## 리서치 과정에서 발견한 것들

### 문제 1: ralph-loop 플러그인이 1회만 실행되고 멈춤
`DONE` 출력 시 completion-promise 달성 = 전체 완료로 해석.
→ bash 스크립트 루프로 전환 (`claude -p` 반복 실행).
공식 플러그인보다 bash 스크립트가 더 안정적이었다.

### 문제 2: AI가 생명 시스템을 만들지 않음
PRD에 "생명이 있는 경우"라고 써놨더니 AI가 생명을 안 넣고 스킵해버림.
→ "최소 3개 생명, 1회 실패 시 1 감소, 0일 때만 게임오버" 강제.
→ 시나리오 4를 "필수, 스킵 불가"로 명시.

**교훈: PRD의 애매한 표현은 AI가 자신에게 유리하게 해석한다.**

### 문제 3: 디자인 빈약
단색 배경 + 단색 도형만으로 구성된 밋밋한 게임.
→ 서브 PRD에 비주얼 디자인 섹션 추가.
→ 인라인 SVG, CSS 그라데이션/그림자, 이모지, Canvas 드로잉 가이드라인.
→ 나쁜 예시 vs 좋은 예시 코드까지 PRD에 포함.

### 발견: 테스트 통과 ≠ 품질 보증
4중 검증을 전부 통과한 게임도 실제 플레이하면 문제가 있었다.
"자동 검증의 커버리지"와 "체감 품질" 사이에는 갭이 존재한다.

---

## PRD 수정 사이클

```
1차: 기본 PRD → 게임 생성되나 즉사 버그 + 디자인 빈약
2차: 생명 시스템 강제 + 디자인 가이드 추가 → 여전히 즉사 (표현 여전히 애매)
3차: "필수, 스킵 불가" 명시 + SVG/이모지/Canvas 비주얼 가이드 추가 → 개선
```

PRD 자체가 프롬프트 엔지니어링이다. PRD 한 줄의 애매함이 게임 품질에 직접 영향을 미친다.
PRD 수정 → 재실행 사이클 자체가 "메타 Ralph Loop"다.

---

## 처음 품었던 의문들

> 사람은 처음부터 완벽한 프롬프트를 줄 수 없는데, 장시간 루프가 정말 의도에 수렴한다고 보장할 수 있는가?

수렴하지 않는다. PRD 품질에 비례한다. 처음에는 발산하고, PRD를 다듬을수록 수렴에 가까워진다.

> 실패 비용이 큰 도메인에서는 자동화 이득보다 사후 검수 비용이 더 커지지 않는가?

실제로 발생했다. 4중 검증을 통과해도 직접 플레이해보면 버그가 있다. 체감 품질 검수는 자동화할 수 없다.

> Ralph Loop는 어떤 문제 유형에서 가장 경제성이 높은가?

"대충 많이 만들기"에는 좋다. 검증 기준이 명확하고 실패 비용이 낮은 반복 생성 작업.
"잘 만들기"는 PRD 정밀도에 비례한다.

---

## 성과

- 첫 게임 생성까지 약 6분
- 4중 검증(유닛 20개 + 린터 + Playwright 7개 + 시나리오 3개) 자동 통과
- games.json 등록, 로그 기록까지 PRD대로 자동 수행
